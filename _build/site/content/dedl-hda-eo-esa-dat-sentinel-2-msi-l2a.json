{"version":2,"kind":"Notebook","sha256":"c2bbfee6ae12f471ba26c0506b30b590c5fba645f29eee582d50c125b2e6ae8e","slug":"dedl-hda-eo-esa-dat-sentinel-2-msi-l2a","location":"/production/HDA/Fresh_Data_Pool/DEDL-HDA-EO.ESA.DAT.SENTINEL-2.MSI.L2A.ipynb","dependencies":[],"frontmatter":{"title":"How to use HDA to find and download data for conducting monitoring of Śniadrwy lake","subtitle":"This notebook demonstrates a simple example of how you can access data from DEDL using HDA and what you can do with it using an example with Sentinel-1 data.","tags":["HDA","STAC","Sentinel-2","satpy"],"copyright":"© 2024 EUMETSAT","authors":[{"id":"Author: Eumetsat","name":"Author: Eumetsat"}],"license":{"content":{"id":"MIT","url":"https://opensource.org/licenses/MIT","name":"MIT License","free":true,"osi":true}},"thumbnail":"../../img/EUMETSAT-icon.png","kernelspec":{"name":"python_dedl","display_name":"Python DEDL","language":"python"},"numbering":{"title":{"offset":1}},"exports":[{"format":"ipynb","filename":"DEDL-HDA-EO.ESA.DAT.SENTINEL-2.MSI.L2A.ipynb","url":"/DEDL-HDA-EO.ESA.DAT.-8fc43773d4c64742256b982e3fe40d9b.ipynb"}]},"widgets":{},"mdast":{"type":"root","children":[{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"In this notebook, we will present a simple example on how you can access data from DEDL using HDA and what you can do with it. As an example, we will try to download Sentinel-2 images containining data of Śniadrwy lake from first week of July 2023. With usage of HDA and few Python packages, you will be able to obtain rasters with NDWI index.","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"IVD3qYvIdt"}],"key":"p5MaGyr4wl"}],"key":"Z9mtwkYR7H"},{"type":"block","kind":"notebook-content","children":[{"type":"heading","depth":2,"position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"1. Prerequisites","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"xIAbRmnsjk"}],"identifier":"id-1-prerequisites","label":"1. Prerequisites","html_id":"id-1-prerequisites","implicit":true,"key":"OhlOHFIzxe"}],"key":"BWBAf82mYX"},{"type":"block","kind":"notebook-content","children":[{"type":"heading","depth":3,"position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"1.1 DestinE account","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"PZTCWQKdV4"}],"identifier":"id-1-1-destine-account","label":"1.1 DestinE account","html_id":"id-1-1-destine-account","implicit":true,"key":"z9hIinix0w"},{"type":"paragraph","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"children":[{"type":"text","value":"Firstly, to work with HDA we will need account on DestinE Core Service Platfrom website. You can register under this url: ","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"qfHkYBJtaa"},{"type":"link","url":"https://platform.destine.eu/","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"children":[{"type":"text","value":"https://​platform​.destine​.eu/","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"GO7MdEluNv"}],"urlSource":"https://platform.destine.eu/","key":"Izm6vdq4Zy"}],"key":"d7zQZlyKBM"}],"key":"oEF4fCuY9b"},{"type":"block","kind":"notebook-content","children":[{"type":"heading","depth":3,"position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"1.2 Python’s packages","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"fZJo3K5dlT"}],"identifier":"id-1-2-pythons-packages","label":"1.2 Python’s packages","html_id":"id-1-2-pythons-packages","implicit":true,"key":"qyKoALhFY4"}],"key":"Uotwlrj9MT"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"import requests\nimport zipfile\nimport io\nimport destinelab as deauth\nfrom getpass import getpass","key":"KcTem0EL28"},{"type":"output","id":"U1AKC8w-G8Lzp3PxPzLqR","data":[],"key":"SpfqATAt0m"}],"key":"dQRa1gXk6m"},{"type":"block","kind":"notebook-content","children":[{"type":"heading","depth":3,"position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"1.3 Prerequiared data","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"imJDAn6Is3"}],"identifier":"id-1-3-prerequiared-data","label":"1.3 Prerequiared data","html_id":"id-1-3-prerequiared-data","implicit":true,"key":"fKlB4s5ZGs"},{"type":"paragraph","position":{"start":{"line":2,"column":1},"end":{"line":2,"column":1}},"children":[{"type":"text","value":"Before reuqesting some data from DEDL HDA, let’s specify what data we want to obtain. We will define 3 variables:","position":{"start":{"line":2,"column":1},"end":{"line":2,"column":1}},"key":"zd09MyqChh"}],"key":"ZiQpNeYHfi"},{"type":"list","ordered":false,"spread":false,"position":{"start":{"line":3,"column":1},"end":{"line":6,"column":1}},"children":[{"type":"listItem","spread":true,"position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"children":[{"type":"text","value":"Start date and end date,","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"ENgYBqh866"}],"key":"lcMCUvrYY0"},{"type":"listItem","spread":true,"position":{"start":{"line":4,"column":1},"end":{"line":4,"column":1}},"children":[{"type":"text","value":"Output directory,","position":{"start":{"line":4,"column":1},"end":{"line":4,"column":1}},"key":"PEZXlyXjtm"}],"key":"oeg67o5jnT"},{"type":"listItem","spread":true,"position":{"start":{"line":5,"column":1},"end":{"line":6,"column":1}},"children":[{"type":"text","value":"Geometry of interesting us area","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"key":"F0RlAYVKgc"}],"key":"KTGR4YGOg5"}],"key":"rcvj5co31X"},{"type":"paragraph","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"children":[{"type":"inlineCode","value":"Start date and end date","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"key":"j2Eo4kitni"},{"type":"text","value":" will define our timerange in reuqest. HDA will search only for products that were obtained between those two dates.","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"key":"l2sSKzAX87"}],"key":"a9dRb4CcJR"},{"type":"paragraph","position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"children":[{"type":"inlineCode","value":"Output directory","position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"key":"o7v41z4Fzj"},{"type":"text","value":" will define directory for downloaded products.","position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"key":"nsmsZYdEA9"}],"key":"f8Vd2lC1KD"},{"type":"paragraph","position":{"start":{"line":11,"column":1},"end":{"line":11,"column":1}},"children":[{"type":"inlineCode","value":"Geometry","position":{"start":{"line":11,"column":1},"end":{"line":11,"column":1}},"key":"OCwKTZRmhe"},{"type":"text","value":" wll define our area of interest. It will be passed as BBOX (Bounding Box), as a list of coordinates - Xmin, Ymin, Xmax, Ymax. All coordinates will be defined in EPSG:4326.","position":{"start":{"line":11,"column":1},"end":{"line":11,"column":1}},"key":"i79eAgawlw"}],"key":"SocDtoTgrb"}],"key":"X7rOmkXsOT"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"# Timerange of data that we want to recieve\nstart_date = '2023-07-01'\nend_date = '2023-07-07'\n# Output directory of our desired data\noutput_dir = 'output/'\n# Geometry in form of a BBOX\nbbox = [21.61868,53.66627,21.90926,53.82351]","key":"YRgjOrdhG1"},{"type":"output","id":"G51cWNOfXngUfLjPtiVQl","data":[],"key":"ZT4Bk9LpgK"}],"key":"QxwSyh9t24"},{"type":"block","kind":"notebook-content","children":[{"type":"heading","depth":2,"position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"2. Work with HDA","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"R0rp7CViJK"}],"identifier":"id-2-work-with-hda","label":"2. Work with HDA","html_id":"id-2-work-with-hda","implicit":true,"key":"wcrzQ4LXBv"},{"type":"paragraph","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"children":[{"type":"text","value":"HDA (Harmonized Data Access) uses STAC protocol, that allows its user access the Earth Observation data, stored in various provides. Thanks to that, HDA serves as an one stream of data, allowing for comfortable work with sattelite imagery.","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"DITZmzgVms"}],"key":"TclCXfMFaj"}],"key":"COsaWiYZ4B"},{"type":"block","kind":"notebook-content","children":[{"type":"heading","depth":2,"position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"2.1 API URLs","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"adgTfJXSvw"}],"identifier":"id-2-1-api-urls","label":"2.1 API URLs","html_id":"id-2-1-api-urls","implicit":true,"key":"nVjVl6RCHy"},{"type":"paragraph","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"children":[{"type":"text","value":"HDA, as all API, is build upon many endpoints. In this notebook we will use only one for collections and searching. Below there are definitions of those endpoints. We will be using the common one site, but you can change it to ","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"h7L4n9nbas"},{"type":"inlineCode","value":"central","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"KFyFOXQ1NX"},{"type":"text","value":", ","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"Glf2uspJZc"},{"type":"inlineCode","value":"lumi","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"BllZMevjeu"},{"type":"text","value":" or ","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"Q1YlAOnFsj"},{"type":"inlineCode","value":"leonardo","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"Sajc9Yyidz"},{"type":"text","value":" if you want.","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"cLXDFlf5ON"}],"key":"R6TniGisu1"}],"key":"p3U70IvZDJ"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"COLLECTIONS_URL = 'https://hda.data.destination-earth.eu/stac/collections'\nSEARCH_URL = 'https://hda.data.destination-earth.eu/stac/search'","key":"rmkanhQctr"},{"type":"output","id":"4ge_PP863Uf68hc-ZTJs3","data":[],"key":"o12QB1rOBe"}],"key":"l2ZMKj9xqt"},{"type":"block","kind":"notebook-content","children":[{"type":"heading","depth":2,"position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"2.2 Listing available collections","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"xBoxmIZLus"}],"identifier":"id-2-2-listing-available-collections","label":"2.2 Listing available collections","html_id":"id-2-2-listing-available-collections","implicit":true,"key":"V8CPClJwKT"},{"type":"paragraph","position":{"start":{"line":2,"column":1},"end":{"line":2,"column":1}},"children":[{"type":"text","value":"Firstly lets see to which collections we can get access, while using HDA.","position":{"start":{"line":2,"column":1},"end":{"line":2,"column":1}},"key":"zpN1vyiNPD"}],"key":"O86FMyahEy"}],"key":"bIooxXNrPi"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"def get_stac_collections(api_url):\n    response = requests.get(api_url)\n    if response.status_code == 200:\n        stac_data = response.json()['collections']\n        collections = [x['id'] for x in stac_data]\n        return collections\n    else:\n        print(f\"Error: {response.status_code} - {response.text}\")\n        return None\n    \nget_stac_collections(COLLECTIONS_URL)","key":"VaRRECAMql"},{"type":"output","id":"KMJ6aFbwx5NB5HZYufCs_","data":[{"output_type":"execute_result","execution_count":9,"metadata":{},"data":{"text/plain":{"content":"['EO.CLMS.DAT.CORINE',\n 'EO.CLMS.DAT.GLO.DMP300_V1',\n 'EO.CLMS.DAT.GLO.FAPAR300_V1',\n 'EO.CLMS.DAT.GLO.FCOVER300_V1',\n 'EO.CLMS.DAT.GLO.GDMP300_V1',\n 'EO.CLMS.DAT.GLO.LAI300_V1',\n 'EO.CLMS.DAT.GLO.NDVI300_V1',\n 'EO.CLMS.DAT.GLO.NDVI_1KM_V2',\n 'EO.CLMS.DAT.SENTINEL-2.HRVPP.VI',\n 'EO.DEM.DAT.COP-DEM_GLO-30-DGED',\n 'EO.DEM.DAT.COP-DEM_GLO-30-DTED',\n 'EO.DEM.DAT.COP-DEM_GLO-90-DGED',\n 'EO.DEM.DAT.COP-DEM_GLO-90-DTED',\n 'EO.ECMWF.DAT.CAMS_EUROPE_AIR_QUALITY_FORECASTS',\n 'EO.ECMWF.DAT.CAMS_EUROPE_AIR_QUALITY_REANALYSES',\n 'EO.ECMWF.DAT.CAMS_GLOBAL_ATMOSHERIC_COMPO_FORECAST',\n 'EO.ECMWF.DAT.CAMS_GLOBAL_EMISSION_INVENTORIES',\n 'EO.ECMWF.DAT.CAMS_GLOBAL_FIRE_EMISSIONS_GFAS',\n 'EO.ECMWF.DAT.CAMS_GLOBAL_GREENHOUSE_GAS_REANALYSIS',\n 'EO.ECMWF.DAT.CAMS_GLOBAL_GREENHOUSE_GAS_REANALYSIS_MONTHLY_AV_FIELDS',\n 'EO.ECMWF.DAT.CAMS_GLOBAL_RADIATIVE_FORCING',\n 'EO.ECMWF.DAT.CAMS_GLOBAL_RADIATIVE_FORCING_AUX',\n 'EO.ECMWF.DAT.CAMS_GLOBAL_REANALYSIS_EAC4',\n 'EO.ECMWF.DAT.CAMS_GLOBAL_REANALYSIS_EAC4_MONTHLY_AV_FIELDS',\n 'EO.ECMWF.DAT.CAMS_GREENHOUSE_GAS_FLUXES',\n 'EO.ECMWF.DAT.CAMS_SOLAR_RADIATION_TIMESERIES',\n 'EO.ECMWF.DAT.CEMS_FIRE_HISTORICAL',\n 'EO.ECMWF.DAT.CEMS_GLOFAS_FORECAST',\n 'EO.ECMWF.DAT.CEMS_GLOFAS_HISTORICAL',\n 'EO.ECMWF.DAT.CEMS_GLOFAS_REFORECAST',\n 'EO.ECMWF.DAT.CEMS_GLOFAS_SEASONAL',\n 'EO.ECMWF.DAT.CEMS_GLOFAS_SEASONAL_REFORECAST',\n 'EO.ECMWF.DAT.CO2_DATA_FROM_SATELLITE_SENSORS_2002_PRESENT',\n 'EO.ECMWF.DAT.DERIVED_GRIDDED_GLACIER_MASS_CHANGE',\n 'EO.ECMWF.DAT.DT_CLIMATE_ADAPTATION',\n 'EO.ECMWF.DAT.DT_EXTREMES',\n 'EO.ECMWF.DAT.EFAS_FORECAST',\n 'EO.ECMWF.DAT.EFAS_HISTORICAL',\n 'EO.ECMWF.DAT.EFAS_REFORECAST',\n 'EO.ECMWF.DAT.EFAS_SEASONAL',\n 'EO.ECMWF.DAT.EFAS_SEASONAL_REFORECAST',\n 'EO.ECMWF.DAT.ERA5_HOURLY_VARIABLES_ON_PRESSURE_LEVELS',\n 'EO.ECMWF.DAT.ERA5_LAND_HOURLY',\n 'EO.ECMWF.DAT.ERA5_LAND_MONTHLY',\n 'EO.ECMWF.DAT.ERA5_MONTHLY_MEANS_VARIABLES_ON_PRESSURE_LEVELS',\n 'EO.ECMWF.DAT.GLACIERS_DISTRIBUTION_DATA_FROM_RANDOLPH_GLACIER_INVENTORY_2000',\n 'EO.ECMWF.DAT.METHANE_DATA_SATELLITE_SENSORS_2002_PRESENT',\n 'EO.ECMWF.DAT.REANALYSIS_ERA5_SINGLE_LEVELS',\n 'EO.ECMWF.DAT.REANALYSIS_ERA5_SINGLE_LEVELS_MONTHLY_MEANS',\n 'EO.ECMWF.DAT.REANALYSIS_UERRA_EUROPE_SINGLE_LEVELS',\n 'EO.ECMWF.DAT.SATELLITE_SEA_ICE_CONCENTRATION',\n 'EO.ECMWF.DAT.SATELLITE_SEA_ICE_EDGE_TYPE',\n 'EO.ECMWF.DAT.SATELLITE_SEA_ICE_THICKNESS',\n 'EO.ECMWF.DAT.SEASONAL_FORECAST_ANOMALIES_ON_PRESSURE_LEVELS_2017_PRESENT',\n 'EO.ECMWF.DAT.SEASONAL_FORECAST_ANOMALIES_ON_SINGLE_LEVELS_2017_PRESENT',\n 'EO.ECMWF.DAT.SEASONAL_FORECAST_DAILY_DATA_ON_PRESSURE_LEVELS_2017_PRESENT',\n 'EO.ECMWF.DAT.SEASONAL_FORECAST_DAILY_DATA_ON_SINGLE_LEVELS_2017_PRESENT',\n 'EO.ECMWF.DAT.SEASONAL_FORECAST_MONTHLY_STATISTICS_ON_PRESSURE_LEVELS_2017_PRESENT',\n 'EO.ECMWF.DAT.SEASONAL_FORECAST_MONTHLY_STATISTICS_ON_SINGLE_LEVELS_2017_PRESENT',\n 'EO.ECMWF.DAT.SEA_LEVEL_DAILY_GRIDDED_DATA_FOR_GLOBAL_OCEAN_1993_PRESENT',\n 'EO.ECMWF.DAT.SIS_HYDROLOGY_METEOROLOGY_DERIVED_PROJECTIONS',\n 'EO.ESA.DAT.SENTINEL-1.L1_GRD',\n 'EO.ESA.DAT.SENTINEL-1.L1_SLC',\n 'EO.ESA.DAT.SENTINEL-2.MSI.L1C',\n 'EO.ESA.DAT.SENTINEL-2.MSI.L2A',\n 'EO.ESA.DAT.SENTINEL-3.OL_2_LFR___',\n 'EO.ESA.DAT.SENTINEL-3.OL_2_LRR___',\n 'EO.ESA.DAT.SENTINEL-3.SL_2_LST___',\n 'EO.ESA.DAT.SENTINEL-3.SR_2_LAN___',\n 'EO.ESA.DAT.SENTINEL-5P.TROPOMI.L1',\n 'EO.ESA.DAT.SENTINEL-5P.TROPOMI.L2',\n 'EO.EUM.CM.METOP.ASCSZFR02',\n 'EO.EUM.CM.METOP.ASCSZOR02',\n 'EO.EUM.CM.METOP.ASCSZRR02',\n 'EO.EUM.DAT.METOP.AMSUL1',\n 'EO.EUM.DAT.METOP.ASCSZF1B',\n 'EO.EUM.DAT.METOP.ASCSZO1B',\n 'EO.EUM.DAT.METOP.ASCSZR1B',\n 'EO.EUM.DAT.METOP.AVHRRGACR02',\n 'EO.EUM.DAT.METOP.AVHRRL1',\n 'EO.EUM.DAT.METOP.GLB-SST-NC',\n 'EO.EUM.DAT.METOP.GOMEL1',\n 'EO.EUM.DAT.METOP.GOMEL1R03',\n 'EO.EUM.DAT.METOP.IASIL1C-ALL',\n 'EO.EUM.DAT.METOP.IASSND02',\n 'EO.EUM.DAT.METOP.IASTHR011',\n 'EO.EUM.DAT.METOP.LSA-002',\n 'EO.EUM.DAT.METOP.MHSL1',\n 'EO.EUM.DAT.METOP.OSI-104',\n 'EO.EUM.DAT.METOP.OSI-150-A',\n 'EO.EUM.DAT.METOP.OSI-150-B',\n 'EO.EUM.DAT.METOP.SOMO12',\n 'EO.EUM.DAT.METOP.SOMO25',\n 'EO.EUM.DAT.MULT.HIRSL1',\n 'EO.EUM.DAT.SENTINEL-3.AOD',\n 'EO.EUM.DAT.SENTINEL-3.FRP',\n 'EO.EUM.DAT.SENTINEL-3.OL_1_EFR___',\n 'EO.EUM.DAT.SENTINEL-3.OL_1_ERR___',\n 'EO.EUM.DAT.SENTINEL-3.OL_2_WFR___',\n 'EO.EUM.DAT.SENTINEL-3.OL_2_WRR___',\n 'EO.EUM.DAT.SENTINEL-3.SL_1_RBT___',\n 'EO.EUM.DAT.SENTINEL-3.SL_2_WST___',\n 'EO.EUM.DAT.SENTINEL-3.SR_1_SRA_A_',\n 'EO.EUM.DAT.SENTINEL-3.SR_1_SRA_BS',\n 'EO.EUM.DAT.SENTINEL-3.SR_1_SRA___',\n 'EO.EUM.DAT.SENTINEL-3.SR_2_WAT___',\n 'EO.GSW.DAT.CHANGE',\n 'EO.GSW.DAT.EXTENT',\n 'EO.GSW.DAT.OCCURRENCE',\n 'EO.GSW.DAT.RECURRENCE',\n 'EO.GSW.DAT.SEASONALITY',\n 'EO.GSW.DAT.TRANSITIONS',\n 'EO.MO.DAT.GLOBAL_ANALYSISFORECAST_BGC_001_028',\n 'EO.MO.DAT.GLOBAL_ANALYSISFORECAST_PHY_001_024',\n 'EO.MO.DAT.GLOBAL_ANALYSISFORECAST_WAV_001_027',\n 'EO.MO.DAT.GLOBAL_MULTIYEAR_BGC_001_033',\n 'EO.MO.DAT.GLOBAL_MULTIYEAR_PHY_ENS_001_031',\n 'EO.MO.DAT.GLOBAL_MULTIYEAR_WAV_001_032',\n 'EO.MO.DAT.INSITU_GLO_PHY_TS_OA_MY_013_052',\n 'EO.MO.DAT.INSITU_GLO_PHY_TS_OA_NRT_013_002',\n 'EO.MO.DAT.INSITU_GLO_PHY_UV_DISCRETE_NRT_013_048',\n 'EO.MO.DAT.MULTIOBS_GLO_BGC_NUTRIENTS_CARBON_PROFILES_MYNRT_015_009',\n 'EO.MO.DAT.MULTIOBS_GLO_BIO_BGC_3D_REP_015_010',\n 'EO.MO.DAT.MULTIOBS_GLO_BIO_CARBON_SURFACE_REP_015_008',\n 'EO.MO.DAT.MULTIOBS_GLO_PHY_MYNRT_015_003',\n 'EO.MO.DAT.MULTIOBS_GLO_PHY_S_SURFACE_MYNRT_015_013',\n 'EO.MO.DAT.MULTIOBS_GLO_PHY_TSUV_3D_MYNRT_015_012',\n 'EO.MO.DAT.MULTIOBS_GLO_PHY_W_3D_REP_015_007',\n 'EO.MO.DAT.OCEANCOLOUR_GLO_BGC_L3_MY_009_103',\n 'EO.MO.DAT.OCEANCOLOUR_GLO_BGC_L3_MY_009_107',\n 'EO.MO.DAT.OCEANCOLOUR_GLO_BGC_L3_NRT_009_101',\n 'EO.MO.DAT.OCEANCOLOUR_GLO_BGC_L4_MY_009_104',\n 'EO.MO.DAT.OCEANCOLOUR_GLO_BGC_L4_MY_009_108',\n 'EO.MO.DAT.OCEANCOLOUR_GLO_BGC_L4_NRT_009_102',\n 'EO.MO.DAT.SEAICE_GLO_SEAICE_L4_NRT_OBSERVATIONS_011_001',\n 'EO.MO.DAT.SEAICE_GLO_SEAICE_L4_NRT_OBSERVATIONS_011_006',\n 'EO.MO.DAT.SEAICE_GLO_SEAICE_L4_REP_OBSERVATIONS_011_009',\n 'EO.MO.DAT.SEALEVEL_GLO_PHY_L4_NRT_008_046',\n 'EO.MO.DAT.SEALEVEL_GLO_PHY_MDT_008_063',\n 'EO.MO.DAT.SST_GLO_SST_L3S_NRT_OBSERVATIONS_010_010',\n 'EO.MO.DAT.SST_GLO_SST_L4_NRT_OBSERVATIONS_010_001',\n 'EO.MO.DAT.SST_GLO_SST_L4_REP_OBSERVATIONS_010_011',\n 'EO.MO.DAT.SST_GLO_SST_L4_REP_OBSERVATIONS_010_024',\n 'EO.MO.DAT.WAVE_GLO_PHY_SWH_L3_NRT_014_001',\n 'EO.MO.DAT.WAVE_GLO_PHY_SWH_L4_NRT_014_003',\n 'EO.MO.DAT.WAVE_GLO_WAV_L3_SPC_NRT_OBSERVATIONS_014_002',\n 'EO.MO.DAT.WIND_GLO_PHY_CLIMATE_L4_MY_012_003',\n 'EO.MO.DAT.WIND_GLO_PHY_L3_MY_012_005',\n 'EO.MO.DAT.WIND_GLO_PHY_L3_NRT_012_002',\n 'EO.MO.DAT.WIND_GLO_PHY_L4_MY_012_006',\n 'EO.MO.DAT.WIND_GLO_PHY_L4_NRT_012_004',\n 'EO.NASA.DAT.LANDSAT.C2_L1',\n 'EO.NASA.DAT.LANDSAT.C2_L2',\n 'STAT.EUSTAT.DAT.GREENHOUSE_GAS_EMISSION_AGRICULTURE',\n 'STAT.EUSTAT.DAT.POP_AGE_GROUP_SEX_NUTS3',\n 'STAT.EUSTAT.DAT.POP_AGE_SEX_NUTS2',\n 'STAT.EUSTAT.DAT.POP_CHANGE_DEMO_BALANCE_CRUDE_RATES_NUTS3',\n 'STAT.EUSTAT.DAT.SHARE_ENERGY_FROM_RENEWABLE']","content_type":"text/plain"}}}],"key":"MVH9KkROGB"}],"key":"SxCbZZf3zI"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"As you can see, there are many dataset, that can be access using just one single tool - HDA. In this notebook we will use only Sentinel-2 images, so our collections will be ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"hv635vBdSg"},{"type":"inlineCode","value":"EO.ESA.DAT.SENTINEL-2.MSI.L1C","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"xb0Yqz5b1d"},{"type":"text","value":" and ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"uWpoLG2Hhb"},{"type":"inlineCode","value":"EO.ESA.DAT.SENTINEL-2.MSI.L2A","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"Ab9gITUkmO"},{"type":"text","value":".","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"O0PhMjG5I1"}],"key":"VaFxiMgzO7"}],"key":"fGgmgRisGx"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"collections = ['EO.ESA.DAT.SENTINEL-2.MSI.L1C', 'EO.ESA.DAT.SENTINEL-2.MSI.L2A']","key":"EUvkRhf00t"},{"type":"output","id":"iLXeupK8nhd00oF4WYMwV","data":[],"key":"fuqwr9sHFJ"}],"key":"es3xqA5fAx"},{"type":"block","kind":"notebook-content","children":[{"type":"heading","depth":3,"position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"2.3 Authorization","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"oUAOO4TmiX"}],"identifier":"id-2-3-authorization","label":"2.3 Authorization","html_id":"id-2-3-authorization","implicit":true,"key":"onsTQgLpJu"},{"type":"paragraph","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"children":[{"type":"text","value":"As stated before, to use HDA you will need an account on DestinE. Using your credentials, you will be able to generate ","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"WWMgEFlMCR"},{"type":"inlineCode","value":"access token","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"avztpaohsc"},{"type":"text","value":", that will be needed in upcoming requests. In listing collections’ cell you didn’t have to create token, because only more advanced requests (like listing, searching and downloading items) need it.","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"OW6Rap55sf"}],"key":"jiD4bwHqen"}],"key":"qipaDarIHn"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"DESP_USERNAME = input(\"Please input your DESP username or email: \")\nDESP_PASSWORD = getpass(\"Please input your DESP password: \")\n\nauth = deauth.AuthHandler(DESP_USERNAME, DESP_PASSWORD)\naccess_token = auth.get_token()\nif access_token is not None:\n    print(\"DEDL/DESP Access Token Obtained Successfully\")\nelse:\n    print(\"Failed to Obtain DEDL/DESP Access Token\")\n\nauth_headers = {\"Authorization\": f\"Bearer {access_token}\"}","key":"p7oQio56gc"},{"type":"output","id":"2iAVS409DPJrtBFOHlZ6K","data":[{"name":"stdout","output_type":"stream","text":"Response code: 200\nDEDL/DESP Access Token Obtained Successfully\n"}],"key":"uKFBQ6meKU"}],"key":"zfiD6ac5b9"},{"type":"block","kind":"notebook-content","children":[{"type":"heading","depth":3,"position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"2.4 Find newest product","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"adBxGM8RWX"}],"identifier":"id-2-4-find-newest-product","label":"2.4 Find newest product","html_id":"id-2-4-find-newest-product","implicit":true,"key":"RPEfPIWFWK"},{"type":"paragraph","position":{"start":{"line":2,"column":1},"end":{"line":2,"column":1}},"children":[{"type":"text","value":"After defining all prerequired data and obtaining access token, we can start searching for interesting us products. To do that, we will firstly create body of a POST request with ours parameters. Then, we will send it to HDA and, if request is successful, we will read from response download link.","position":{"start":{"line":2,"column":1},"end":{"line":2,"column":1}},"key":"DfU8J5t1Bg"}],"key":"OaMJGU7a0W"}],"key":"cNKnvFQIJd"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"def search_items(access_token: str, search_url: str, collection: str, \n                 bbox: list[float | int], start_date: str, end_date: str):\n    body = {\n        'datetime': f'{start_date}T00:00:00Z/{end_date}T23:59:59Z',\n        'collections': [collection],\n        'bbox': bbox\n    }\n    response = requests.post(search_url, json=body, headers={'Authorization': 'Bearer {}'.format(access_token)})\n    if response.status_code != 200:\n        print(f'Error in search request: {response.status_code} - {response.text}')\n        return None\n    else:\n        print(\"Request successful! Reading data...\")\n        products_list = [(feature.get('assets').get('downloadLink').get('href'), feature.get('links')[0].get('title')) for feature in response.json().get('features', [])]\n        return products_list","key":"a3QTvHIsOL"},{"type":"output","id":"1HY5XLovaP4rjAOcqExRT","data":[],"key":"heGfhy6qJ3"}],"key":"oKHY2jZJKd"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"To obtain products from two levels of Sentinel-2 - L2A and L1C, we will use loop, iterating over every single collection.","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"CutVHQURBu"}],"key":"XLvBbCir4E"}],"key":"issWdD0ceC"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"collections_items = []\nfor c in collections:\n    collections_items.append(search_items(access_token, SEARCH_URL, c, bbox, start_date, end_date))","key":"LFZ4G597HC"},{"type":"output","id":"6IMHYxqRVE_qowMLL34IB","data":[{"name":"stdout","output_type":"stream","text":"Request successful! Reading data...\nRequest successful! Reading data...\n"}],"key":"nkfHAKQmVz"}],"key":"k7akOpIDxV"},{"type":"block","kind":"notebook-content","children":[{"type":"heading","depth":3,"position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"2.5 Download founded images","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"lfZb6CxuYx"}],"identifier":"id-2-5-download-founded-images","label":"2.5 Download founded images","html_id":"id-2-5-download-founded-images","implicit":true,"key":"BIl674Zsq3"},{"type":"paragraph","position":{"start":{"line":2,"column":1},"end":{"line":2,"column":1}},"children":[{"type":"text","value":"After obtaining download links for each of interesting us product, we can finally download it. With single request, we will download compressed product in zip format to provided directory. Function will set filename as product’s id. Mind that Sentinel-2 products might be over 1 GB, so it may take a few minutes to download them, based on your internet connection.","position":{"start":{"line":2,"column":1},"end":{"line":2,"column":1}},"key":"sMxnV78fmm"}],"key":"KZzWfDcmer"}],"key":"WzIoOJYdEq"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"def hda_download(access_token: str, url: str, output: str):\n    response = requests.get(url,stream=True,headers={'Authorization': 'Bearer {}'.format(access_token), 'Accept-Encoding': None})\n    if response.status_code == 200:\n        print('Downloading dataset...')\n        with zipfile.ZipFile(io.BytesIO(response.content)) as z:\n            z.extractall(output)\n        print('The dataset has been downloaded to: {}'.format(output))\n    else:\n        print('Request Unsuccessful! Error-Code: {}'.format(response.status_code))","key":"t913YFNkRe"},{"type":"output","id":"5rT_fO4hbgiV2X0E8jA3b","data":[],"key":"Dy7jW0mPc2"}],"key":"K7Vu9d7CvE"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"From previous section, we obtained 2D list - with one dimension being collection and second being one item (single product). Becouse of that, we will use two loops to iterate over single products.","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"uULiAZAv4t"}],"key":"Fss83Aa3Nh"}],"key":"L74tMDwB4X"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"for collection in collections_items:\n    for item in collection:\n        url = item[0]\n        product_id = item[1]\n        download_path = output_dir + product_id\n        hda_download(access_token, url, download_path)\n        break","key":"YI5ONWqjXI"},{"type":"output","id":"aOQRkuSqF9GwsxYrO8Jfj","data":[{"name":"stdout","output_type":"stream","text":"Downloading dataset...\nThe dataset has been downloaded to: output/S2B_MSIL1C_20230701T094549_N0509_R079_T34UEE_20230701T104205\nDownloading dataset...\nThe dataset has been downloaded to: output/S2B_MSIL2A_20230701T094549_N0509_R079_T34UEE_20230701T113400\n"}],"key":"LyeuTSR34d"}],"key":"vUK0cKEU2D"},{"type":"block","kind":"notebook-content","children":[{"type":"heading","depth":2,"position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"4. Simple data computing - obtaining NDWI","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"lVY31UssYG"}],"identifier":"id-4-simple-data-computing-obtaining-ndwi","label":"4. Simple data computing - obtaining NDWI","html_id":"id-4-simple-data-computing-obtaining-ndwi","implicit":true,"key":"d7eQCpU7i9"},{"type":"paragraph","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"children":[{"type":"text","value":"In this chapter we will conduct simple data computing. As stated before, this notebook concentrate on monitoring of Śniadrwy lake, so we will try to calculate NDWI index for each pixel and create raster from it. Using all downloaded items, we will be able to monitor lake status from entire month.","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"BwnHWp1BKq"}],"key":"TBEUxp1W4k"}],"key":"hrDdaUFvIu"},{"type":"block","kind":"notebook-content","children":[{"type":"heading","depth":3,"position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"4.1 Libraries","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"mfDVUnP412"}],"identifier":"id-4-1-libraries","label":"4.1 Libraries","html_id":"id-4-1-libraries","implicit":true,"key":"tHS0hNenkm"},{"type":"paragraph","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"children":[{"type":"text","value":"In this chapter we will try to compute obtained by us imagery data, with usage of Python and its spatial-oriented packages.","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"UzbnkAVW27"}],"key":"NbX5uZk4nN"}],"key":"tGgxeMfyLY"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"import rasterio\nfrom osgeo import gdal, gdal_array, osr\nimport numpy as np\nimport os","key":"fmY4uNDqLp"},{"type":"output","id":"qQKg_RNEozi8j-krTP13Z","data":[],"key":"WjLnLlVTeA"}],"key":"tccIYv4gB6"},{"type":"block","kind":"notebook-content","children":[{"type":"heading","depth":3,"position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"4.2 Functions for reading, calculating and saving raster data","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"TjLuBK0zJE"}],"identifier":"id-4-2-functions-for-reading-calculating-and-saving-raster-data","label":"4.2 Functions for reading, calculating and saving raster data","html_id":"id-4-2-functions-for-reading-calculating-and-saving-raster-data","implicit":true,"key":"zJfrCqqVU3"},{"type":"paragraph","position":{"start":{"line":2,"column":1},"end":{"line":2,"column":1}},"children":[{"type":"text","value":"Here we present you some functions for reading raster data into Numpy matrix, calculating NDWI with NIR and GREEN matrixes and saving result as a new raster. We will conduct such calculation for each downloaded item. In the end, we will obtain NDWI data on Śniadrwy Lake from whole week.","position":{"start":{"line":2,"column":1},"end":{"line":2,"column":1}},"key":"bzIX0u4QQS"}],"key":"K4lB2Bmulv"}],"key":"nhmkx08R7A"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"def getFullPath(dir: str, resolution: int, band: str):\n    if not os.path.isdir(dir):\n        raise ValueError(f\"Provided path does not exist: {dir}\")\n    elif resolution not in [10,20,60]:\n        raise ValueError(f\"Provided resolution does not exist: R{resolution}m\")\n    else:\n        full_path = dir\n        while True:\n            content = os.listdir(full_path)\n            if len(content) == 0:\n                raise ValueError(f\"Directory empty: {full_path}\")\n            elif len(content) == 1:\n                if full_path[-1] != '/':\n                    full_path = full_path + '/' + content[0]\n                else:\n                    full_path = full_path + content[0]\n            else:\n                if 'GRANULE' in content:\n                    full_path = full_path + '/' + 'GRANULE'\n                    break\n                else:\n                    raise ValueError(f\"Unsupported dir architecture: {full_path}\")\n        full_path = full_path + '/' + os.listdir(full_path)[0]\n        full_path = full_path + '/' + \"IMG_DATA\"\n        if len(os.listdir(full_path)) == 3:\n            full_path = full_path + '/' + f'R{resolution}m'\n            images = os.listdir(full_path)\n            for img in images:\n                if band in img:\n                    return full_path + '/' + img\n            raise ValueError(f'No such band {band} in directory: {full_path}')\n        else:\n            images = os.listdir(full_path)\n            for img in images:\n                if band in img:\n                    return full_path + '/' + img\n            raise ValueError(f'No such band {band} in directory: {full_path}')\n\n# Get transformation matrix from raster\ndef getTransform(pathToRaster):\n    dataset = gdal.Open(pathToRaster)\n    transformation = dataset.GetGeoTransform()\n    return transformation\n\n# Read raster and return pixels' values matrix as int16, new transformation matrix, crs\ndef readRaster(path, resolution, band):\n    path = getFullPath(path, resolution, band)\n    trans = getTransform(path) # trzeba zdefiniować który kanał\n    raster, crs = rasterToMatrix(path)\n    return raster.astype(np.int16), crs, trans\n\ndef rasterToMatrix(pathToRaster):\n    with rasterio.open(pathToRaster) as src:\n        matrix = src.read(1)\n    return matrix, src.crs.to_epsg()\n\n# Transform numpy's matrix to geotiff; pass new raster's filepath, matrix with pixels' values, gdal file type, transformation matrix, projection, nodata value\ndef npMatrixToGeotiff(filepath, matrix, gdalType, projection, transformMatrix, nodata = None):\n    driver = gdal.GetDriverByName('Gtiff')\n    if len(matrix.shape) > 2:\n        (bandNr, yRes, xRes) = matrix.shape\n        image = driver.Create(filepath, xRes, yRes, bandNr, gdalType)\n        for b in range(bandNr):\n            b = b + 1\n            band = image.GetRasterBand(b)\n            if nodata is not None:\n                band.SetNoDataValue(nodata)\n            band.WriteArray(matrix[b-1,:,:])\n            band.FlushCache\n    else:\n        bandNr = 1\n        (yRes, xRes) = matrix.shape\n        image = driver.Create(filepath, xRes, yRes, bandNr, gdalType)\n        print(type(image))\n        band = image.GetRasterBand(bandNr)\n        if nodata is not None:\n            band.SetNoDataValue(nodata)\n        band.WriteArray(matrix)\n        band.FlushCache\n    image.SetGeoTransform(transformMatrix)\n    image.SetProjection(projection)\n    del driver, image, band","key":"tnbAHFkAgR"},{"type":"output","id":"w5-nE9cPoKQ7K090xuuXy","data":[],"key":"vPiCyCQvUc"}],"key":"JQiUuMiPzN"},{"type":"block","kind":"notebook-content","children":[{"type":"heading","depth":3,"position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"4.3 Computing","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"PBXfLEZZWZ"}],"identifier":"id-4-3-computing","label":"4.3 Computing","html_id":"id-4-3-computing","implicit":true,"key":"UCpcWQugAl"},{"type":"paragraph","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"children":[{"type":"text","value":"With usage of defined functions, we will now generate NWDI rasters. Only data that will be needed in this step is a list with paths to our products (extracted from zip archive). Function ","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"rzRqbGBC4Y"},{"type":"inlineCode","value":"readRaster","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"fAki6QYWI8"},{"type":"text","value":" will choose specified band from specified path.","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"kXVPcKLynl"}],"key":"RyfXq4SxDZ"}],"key":"aZiiPu0WsF"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"# List of products' paths. If your output directory contains more than just downloaded products, please provide them in a list, just like in the commented lines below\n#dataset = [output_dir+x for x in os.listdir(output_dir)]\ndataset = [\n     'output/S2B_MSIL1C_20230701T094549_N0509_R079_T34UEE_20230701T104205'\n ]\n# Output directiry for new images\ncompution_output = 'output/ndwi_rasters'\n\n# Iterating over single product\nfor item in dataset:\n    # Reading name from path\n    name = item.split('/')[-1]\n    # Reading green band into matrix\n    green = readRaster(item, 10, 'B03')\n    # Reading NIR band into matrix\n    nir = readRaster(item, 10, 'B08')\n    # Calculating NDWI matrix\n    ndwi = (green[0]-nir[0]) / (green[0]+nir[0])\n    # Setting treshhold for water-containing pixels\n    ndwi[ndwi >= 0] = 1\n    ndwi[ndwi < 0] = 0\n    # Creating SpatialReference object and setting it to match original's raster CRS\n    projection = osr.SpatialReference()\n    projection.ImportFromEPSG(green[1])\n    # Creating raster from matrix in GeoTiff format\n    npMatrixToGeotiff(f'{compution_output}/{name}.tif', ndwi, gdal_array.NumericTypeCodeToGDALTypeCode(np.float32), projection.ExportToWkt(), green[2])","key":"rXWFeWivSP"},{"type":"output","id":"4Ay2K8gZ6N7Tzpr5-Ruiz","data":[{"name":"stderr","output_type":"stream","text":"/tmp/ipykernel_14887/1055239620.py:18: RuntimeWarning: invalid value encountered in divide\n  ndwi = (green[0]-nir[0]) / (green[0]+nir[0])\n"},{"name":"stdout","output_type":"stream","text":"<class 'osgeo.gdal.Dataset'>\n"}],"key":"Le6ZffPdrJ"}],"key":"gOingUbkUC"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"After successfuly creating and saving new images, we can now visualize them in Python using raterio package.","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"NzoSZs05HB"}],"key":"TnuPvAL5nt"}],"key":"rXEN5LICpd"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"img = rasterio.open('output/ndwi_rasters/S2B_MSIL1C_20230701T094549_N0509_R079_T34UEE_20230701T104205.tif')\nfrom rasterio.plot import show\nshow(img)","key":"rQbeFxiRNI"},{"type":"output","id":"PKBhHtRNVsI5fP_3HgYjJ","data":[{"output_type":"display_data","metadata":{},"data":{"image/png":{"content_type":"image/png","hash":"e22a918acd9ca9a355be23b1af5f5b37","path":"/e22a918acd9ca9a355be23b1af5f5b37.png"},"text/plain":{"content":"<Figure size 640x480 with 1 Axes>","content_type":"text/plain"}}},{"output_type":"execute_result","execution_count":40,"metadata":{},"data":{"text/plain":{"content":"<Axes: >","content_type":"text/plain"}}}],"key":"iJ6byq756L"}],"key":"wJ0lWHOkkw"}],"key":"BOvBy0pDE2"},"references":{"cite":{"order":[],"data":{}}}}